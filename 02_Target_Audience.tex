\section{Target Audience, Prerequisites and Learning Goals}
Recent years have seen increasing interest in Relational AI within the KR community. This interest is reflected in consistent StarAI related events in previous editions of KR, including David Poole's 2020 keynote speech  on StarAI, and the tutorial of Braun, Gehrke and Wilhelm at KR 2023. In this tutorial, we will bring to attention some foundational problems in StarAI. Hence, our tutorial will be of interest to the existing StarAI community at KR. Furthermore, our tutorial is also interesting to the community of complexity analysis of reasoning. As it will contain a thorough introduction to key ideas behind tractable WFOMC. We believe that this tutorial can be attended by anyone with basic knowledge of probability and first order logic. 

The attendees will learn about the relation between problems like: model counting and probabilistic inference; the complexity of model counting problems; and about fragments of first order logic that admit tractable WFOMC. The tutorial will guide the audience through some of the key combinatorial ideas behind tractable WFOMC. The tutorial will also discuss the current state-of-the-art first-order model counters, their applications and their inefficiencies. The audience will be made aware of both  theoretical and practical open-problems, whose resolution would lead to efficient probabilistic inference and learning in StarAI models.




The attendees will also be introduced to the problem of consistency of inference, and the recently developed theories of StarAI models that admit consistent parameter estimation. Such models, also known as \emph{projective models}, open up a vast array of new avenues in StarAI, and the tutorial will provide the audience with the most recent developments. The audience will gain deep understanding of present theoretical models of projectivity and their recent applications. Finally, we will also discuss some recent results on domain-size generalization of non-projective models, and discuss how simple techniques like parameter re-scaling and regularization lead to provably better generalization across domain sizes.


%%% mode: latex
%%% TeX-master: "main"
%%% End:
